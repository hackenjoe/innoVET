{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff5f55f",
   "metadata": {},
   "source": [
    "(modelling)=\n",
    "\n",
    "# Modellierung\n",
    "```{admonition} Erklärung zum Prozessschritt (Aufklappen)\n",
    ":class: dropdown\n",
    "Dieser Teil stellt den Kern der Datenanalyse dar. Eine datengetriebene KI-Lösung erfordert immer ein Lernmodell. Dieses Lernmodell gilt es mit ausreichend hoher Datenmengen zu trainieren. Durch das Training wird das Lernmodell besser in der Ausführung seiner Aufgabe. Entscheidend hier ist die Auswahl eines geeigneten Modells, dass am besten die Anforderungen aus der Problembeschreibung erfüllt. Wie das Schaubild aus S.1 zeigt, kann die Modellierung zur Folge haben, dass von hier aus ein Schritt zurück in die Datenaufbereitungsphase gesprungen werden muss (beispielsweise wenn die Daten nicht wie geplant für das Modell funktionieren oder das gewählte Lernmodell bestimmte Eigenschaften an den Daten nachträglich voraussetzt). Daher sind die zentralen Schritte in dieser Phase:\n",
    "\n",
    "* Auswahl eines geeigneten Modells und dessen Implementierung\n",
    "* Erstellung eines Testmodells zur Verifikation\n",
    "* Modellbewertung im Hinblick auf die betriebswirtschaftliche Problemstellung\n",
    "\n",
    "Die THU bietet verschiedene Modellentwicklungen für die unterschiedlichsten Problemstellungen an. Gerne setzen wir uns mit Ihnen zusammen, um gemeinsam ein geeignetes individuelles Modell für Ihre Problemstellung zu formulieren.\n",
    "```\n",
    "\n",
    "```{admonition} Handwerkerbewertungen:\n",
    ":class: tip\n",
    "Für die Handwerkerbewertungen eignet sich hier insbesondere ein Klassifizierungsmodell aus dem Bereich der natürlichen Sprachverarbeitung, da hier Freitexte von Kunden verwendet werden, die keine näheren Limitierungen aufweisen.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435b06e0",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pascal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4 stars'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "from sentimental_imports import *\n",
    "from sentimental_class import SentimentModel\n",
    "\n",
    "# Auswahl des Modells\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# Einen Tokenizer für das Modell\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Eine Pipeline, die alles verbindet und die Bedienbarkeit vereinfacht\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=0 if str(device) == 'cuda' else -1)\n",
    "# Simpler Test\n",
    "classifier(\"Ich finde, dass die Handwerksbetriebe gute Arbeit vollrichten\")[0]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9fd95",
   "metadata": {},
   "source": [
    "Wie wir sehen können, wurde unser Testbeispiel mit einer Bewertung von $4$ Sternen bewertet. Ändern wir nun eine kleine Stelle in diesem Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b1ec88",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 stars'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Ich finde, dass die Handwerksbetriebe sehr gute Arbeit vollrichten\")[0]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc85f78",
   "metadata": {},
   "source": [
    "Durch die Änderung von *gut* durch *sehr gut* hat sich das Rating um einen Stern verbessert. Dies ist intuitiv auch nachvollziehbar, da eine gute Bewertung eben noch keine sehr gute Bewertung darstellt. Das Modell scheint also auch für deutsche Texte zu funktionieren. Für unseren Anwendungsfall, wollen wir ja nur wissen, ob jemand etwas positives, neutrales oder negatives geschrieben hat. Also sollten wir noch ein paar kleinere Ergänzungen einfügen und diese am besten kompakt in einer Klasse integrieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00374add",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miserabler Handwerker! --> negative Bewertung\n",
      "aber insgesamt bin ich sehr zufrieden --> positive Bewertung\n",
      "Das war unfair --> negative Bewertung\n",
      "Das ist gar nicht mal so gut --> negative Bewertung\n",
      "Total awesome! --> positive Bewertung\n",
      "nicht so schlecht wie erwartet --> neutrale Bewertung\n",
      "Das ist gar nicht mal so schlecht --> negative Bewertung\n",
      "Der Test verlief positiv. --> positive Bewertung\n",
      "Der Verputzer hat die Arbeit ganz okay ausgeführt. --> neutrale Bewertung\n",
      "Der Elektriker war sehr zuvorkommend. Gerne wieder! --> positive Bewertung\n"
     ]
    }
   ],
   "source": [
    "bewertungstexte = [\"Miserabler Handwerker!\", \"aber insgesamt bin ich sehr zufrieden\", \"Das war unfair\", \"Das ist gar nicht mal so gut\",\n",
    "                   \"Total awesome!\",\"nicht so schlecht wie erwartet\", \"Das ist gar nicht mal so schlecht\",\n",
    "                   \"Der Test verlief positiv.\", \"Der Verputzer hat die Arbeit ganz okay ausgeführt.\", \"Der Elektriker war sehr zuvorkommend. Gerne wieder!\"]\n",
    "\n",
    "model_b = SentimentModel(model_name)\n",
    "\n",
    "for i,j in zip(bewertungstexte, model_b.predict_sentiment(bewertungstexte)):\n",
    "    print(f'{i} --> {j}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e422a",
   "metadata": {},
   "source": [
    "Das sieht schon sehr gut aus! Wir können offenbar kurze Texte bereits klassifizieren. Die Testbewertungen würden wir als Mensch ebenso interpretieren. Dennoch, um ein wirklich zuverlässiges Modell auch für längere oder komplizierterer Bewertungstexte zu valideren, benötigen wir noch mehr Daten. Glücklicherweise haben wir ja unsere aufbereiteten Handwerkerbewertungen. Guter Zeitpunkt, um diese Daten mit unserem neuen Modell zu testen.\n",
    "\n",
    "```{admonition} Hinweis:\n",
    ":class: note\n",
    "Das geladene Modell ist ein starkes vortrainiertes Modell mit einem ausreichend großen Textkorpus (u.a. mehrsprachig und mit $137.000$ deutscher Produktbewertungen trainiert). Die *Handwerkerbewertungen* sind jedoch nicht Teil dieses Modells. Daher wird diese Art des Lernens auch als *transferes Lernen* bezeichnet. Denn wir wenden das Modell für Daten einer Klasse an, die es zuvor noch nie gesehen hat. \n",
    "```\n",
    "\n",
    "```{exercise} Ihre Aufgaben\n",
    ":class: dropdown\n",
    ":nonumber: true\n",
    "* Aus dem Code ist ersichtlich, dass ein *Tokenizer* für das Modell verwendet wird. Was ist darunter zu verstehen? Warum benötigen wir sowas und wie sehen die Texte nach der Tokenisierung für BERT aus?\n",
    "* Welche Vorteile ergeben sich aus dem Einsatz von `cuda`? Prüfen Sie Ihre PyTorch Installation auf Unterstützung von CUDA.\n",
    "* Laden Sie das vortrainierte Modell [**BERT-base-multilingual-uncased-sentiment**](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment) in ein neues Python Skript und testen Sie eigene Bewertungstexte.\n",
    "* Finden Sie Sätze die Ihrer Meinung nach einer anderen Gefühlslage entsprechen sollten? Wenn ja, woran könnte das Problem liegen?\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "source_map": [
   10,
   33,
   56,
   60,
   69,
   73,
   89
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}